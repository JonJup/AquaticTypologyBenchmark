<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="03_methods_files/libs/clipboard/clipboard.min.js"></script>
<script src="03_methods_files/libs/quarto-html/quarto.js"></script>
<script src="03_methods_files/libs/quarto-html/popper.min.js"></script>
<script src="03_methods_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="03_methods_files/libs/quarto-html/anchor.min.js"></script>
<link href="03_methods_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="03_methods_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="03_methods_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="03_methods_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="03_methods_files/libs/bootstrap/bootstrap-8a79a254b8e706d3c925cde0a310d4f0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<section id="the-data-sets" class="level3">
<h3 class="anchored" data-anchor-id="the-data-sets">The data sets</h3>
<!-- provenance of data -->
<!-- subsampling -->
<p>Within each data set, we will stratify the subsampling by year. Within each year, we will restrict it to the three consective months with the most samples. If these number of samples in these months (<span class="math inline">\(N_{months}\)</span>) &lt; 100 samples, this year will not be evaluated for this data set. If <span class="math inline">\(N_{months} \ge 100\)</span> samples, our subsampling methodology will incorporate a descending-frequency approach based on one hundred-sample increments. The process will begin by dividing <span class="math inline">\(N_{months}\)</span> by 100 (rounded down) to determine the number of increments <span class="math inline">\(N_{inc}\)</span>. For each increment <span class="math inline">\(i\)</span> from 1 to <span class="math inline">\(N_{inc}\)</span>, we will generate <span class="math inline">\((N_{inc} - (i-1))\)</span> independent subsamples, each containing <span class="math inline">\(i \times 100\)</span> samples. When the remainder from dividing <span class="math inline">\(N_{months}\)</span> by 100 exceeds 0.5, we will include one additional sample at the maximum size. This approach ensures thorough sampling coverage while maintaining computational feasibility. For each subsample we determined the minimum, mean, median, and maximum spatial distance between samples with the R package sf (ref). We then remove taxa that occur in less than 5% of sampling sites.</p>
</section>
<section id="environmental-data" class="level3">
<h3 class="anchored" data-anchor-id="environmental-data">Environmental data</h3>
<p>We will compile and extensive data base of environmental variables relevant for freshwater organisms (Table 1). Each variable will be summarized at the catchment scale, where catchments are derived from the EU hydro DEM catchment data base (REF).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Spatial Scale</th>
<th>Data product</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Rainfall erosivity</td>
<td>Ecosystem</td>
<td>GloREDa</td>
<td>Panagos et al.&nbsp;(2023)</td>
</tr>
<tr class="even">
<td>Soil Organic Carbon</td>
<td>Ecosystem</td>
<td>European Soil Database v2.0</td>
<td>Panagos et al.&nbsp;(2022)</td>
</tr>
<tr class="odd">
<td>Soil pH in Water</td>
<td>Ecosystem</td>
<td>EcoDataCube</td>
<td>Witjes et al.&nbsp;(2023)</td>
</tr>
<tr class="even">
<td>Slope</td>
<td>Ecosystem</td>
<td>Hydrography90m</td>
<td>Amatulli et al.&nbsp;(2022)</td>
</tr>
<tr class="odd">
<td>Roughness</td>
<td>Ecosystem</td>
<td>Geomorpho90m</td>
<td>Amatulli et al.&nbsp;(2020)</td>
</tr>
<tr class="even">
<td>Floodplain Area</td>
<td>Ecosystem</td>
<td>Potential Flood prone Area</td>
<td>EEA (2020)</td>
</tr>
<tr class="odd">
<td>Mean annual discharge</td>
<td>Ecosystem</td>
<td>Copernicus C3S</td>
<td>Berg et al.&nbsp;(2021)</td>
</tr>
<tr class="even">
<td>Minimum annual discharge</td>
<td>Ecosystem</td>
<td>Copernicus C3S</td>
<td>Berg et al.&nbsp;(2021)</td>
</tr>
<tr class="odd">
<td>Saturated Soil Water Content</td>
<td>Ecosystem</td>
<td>Soil Hydraulic Properties</td>
<td>Tóth et al.&nbsp;(2015)</td>
</tr>
<tr class="even">
<td>Upstream catchment area</td>
<td>Ecosystem</td>
<td>HydroATLAS</td>
<td>Linke et al (2019)</td>
</tr>
<tr class="odd">
<td>Maximum annual discharge</td>
<td>Ecosystem</td>
<td>Copernicus C3S</td>
<td>Berg et al.&nbsp;(2021)</td>
</tr>
<tr class="even">
<td>Snow Cover</td>
<td>Ecosystem</td>
<td>HydroATLAS</td>
<td>Linke et al (2019)</td>
</tr>
<tr class="odd">
<td>Segment Sinuosity</td>
<td>Ecosystem</td>
<td>EU Hydro</td>
<td>EEA (2019)</td>
</tr>
<tr class="even">
<td>Valley Bottom Flatness Index</td>
<td>Ecosystem</td>
<td>EcoDataCube</td>
<td>Witjes et al.&nbsp;(2023)</td>
</tr>
<tr class="odd">
<td>Stream Power Index</td>
<td>Ecosystem</td>
<td>Hydrography90m</td>
<td>Amatulli et al.&nbsp;(2022)</td>
</tr>
<tr class="even">
<td>Lake Index</td>
<td>Ecosystem</td>
<td>HydroLAKES</td>
<td>Messager et al.&nbsp;(2016); Snelder et al.&nbsp;(2005)</td>
</tr>
<tr class="odd">
<td>Elevation</td>
<td>Region, Ecosystem</td>
<td>Hydrography90m</td>
<td>Amatulli et al.&nbsp;(2022)</td>
</tr>
<tr class="even">
<td>Groundwater Table Depth</td>
<td>Region</td>
<td>HydroATLAS</td>
<td>Linke et al.&nbsp;(2019)</td>
</tr>
<tr class="odd">
<td>Glaciated Area in Catchment</td>
<td>Region</td>
<td>Randolph Glacier Inventory</td>
<td>RGI Consortium (2017)</td>
</tr>
<tr class="even">
<td>Precipitation of Wettest Month</td>
<td>Region</td>
<td>CHELSA-BIOCLIM+</td>
<td>Brun et al.&nbsp;(2022)</td>
</tr>
<tr class="odd">
<td>Precipitation of Driest Month</td>
<td>Region</td>
<td>CHELSA-BIOCLIM+</td>
<td>Brun et al.&nbsp;(2022)</td>
</tr>
<tr class="even">
<td>Minimum Temperature Coldest Month</td>
<td>Region</td>
<td>CHELSA-BIOCLIM+</td>
<td>Brun et al.&nbsp;(2022)</td>
</tr>
<tr class="odd">
<td>Maximum Temperature Warmest Month</td>
<td>Region</td>
<td>CHELSA-BIOCLIM+</td>
<td>Brun et al.&nbsp;(2022)</td>
</tr>
<tr class="even">
<td>Bedrock Geology</td>
<td>Region</td>
<td>IHME</td>
<td>Cornu et al.&nbsp;(2013)</td>
</tr>
<tr class="odd">
<td>Catchment soil type</td>
<td>Region</td>
<td>European Soil Database v2.0</td>
<td>Panagos et al.&nbsp;(2022)</td>
</tr>
</tbody>
</table>
<!-- Space -->
<p>We will capture the impact of space using one of two different approaches: Moran’s Eigenvector Maps (MEM, ref) or Asymmetric Eigenvector Maps (AEM, ref). (ref) MEM will be used of the largest spatial distance within a subsample exceeds T, otherwise we will use AEM. For both we will evaluate the statistical significance of Moran’s I of the eigenvectos with permutation tests <span class="citation" data-cites="cliffSpatialAutocorrelation1973">[@cliffSpatialAutocorrelation1973]</span>, and only keept those eigenvectors which had a statistically significant Moran’s I value. Both will be implemented with the adespatial R package version … (ref).</p>
</section>
<section id="modellings-species-communities" class="level3">
<h3 class="anchored" data-anchor-id="modellings-species-communities">Modellings species communities</h3>
<!-- describe HMSC setup -->
<p>To establish the relationship between the presence/ absence of organisms and environmental variables, we will use hierarchical modelling of species communities (HMSC, ref) from the corresponding R package Hmsc (ref). This bayesian hierarchical latent variable model allows the incorporation of phylogeny and traits and has been favoribly compared to similar methdods (ref).<br>
We will include a non-spatiotemporal random factor for each sample. The model will be fit with a probit residual distribution. <!-- TODO --> Model fit will be evaluated with the potential scale reduction factor and choose a second statistic. By default, we will run models with two chains, 2000 samples, a thinning of 2, and a transient period of 2000 samples. If either of potential scale reduction factor or Welch’s statistic suggest that the chains have not converged or that the posterior is not stationary for &gt; 10% of regression parameters, we will iteratively increase the number of samples up to 10000. Thinning will be increased in parallel, so that it is awlways the number of chains devided by 1000, and the length of the transient equals the number of samples.</p>
<!-- Traits and phenology where available -->
<p>Where available, we include both functional traits and phylogenetic data in the HMSC model. For fish, funcitonal data is available through Traits of Freshwater Fish <span class="citation" data-cites="lecocqTOFFDatabaseTraits2019">[TOFF, @lecocqTOFFDatabaseTraits2019]</span> and the phylogenetic data from <span class="citation" data-cites="raboskyInverseLatitudinalGradient2018">@raboskyInverseLatitudinalGradient2018</span>. For diatoms, … . For macroinvertebrates, functional data is available through <span class="citation" data-cites="kunzTacklingInconsistenciesFreshwater2022">@kunzTacklingInconsistenciesFreshwater2022</span>, but highly resolved phylogenetic data is only available for certain orders <span class="citation" data-cites="garcia-gironTimecalibratedTreeLife2024">[see @garcia-gironTimecalibratedTreeLife2024]</span>. For macrophytes,</p>
<!-- describe variation partioning -->
<p>Rather than evaluating the explained variation based on point estimates derived from the parameter’s posterior distribution, we will compute the full posterior of the VP (see ref) and use point estiamtes from the latter. Due to Jensen’s inequality these two values are not equal.</p>
<p>We will interpret all the variance explained by environmental variables as abiotic filering, the variance explained by spatial eigenvectors as spatial filtering, and the variance of the latent variables as biotic interactions. The last point is highly contentions <span class="citation" data-cites="blanchetCooccurrenceNotEvidence2020 dormannBioticInteractionsSpecies2018 valleSpeciesAssociationsJoint2023">[e.g., @blanchetCooccurrenceNotEvidence2020; @dormannBioticInteractionsSpecies2018; @valleSpeciesAssociationsJoint2023]</span>, as the latent variables can also captured unmeasured enviornmental driveres. In our case this will likely include local scale variables such as sediment composition. We expect therefore to slightly overestimate the relevance of biotic interactions and will keep this in mind in any interpretations of the results. Tjur’s <span class="math inline">\(R^2\)</span> <span class="citation" data-cites="tjurCoefficientsDeterminationLogistic2009">[@tjurCoefficientsDeterminationLogistic2009]</span> will be used to evaluate the overall explained variation in the biotic data.<br>
The unexplained variance <span class="math inline">\(1-R^2_{Tjur}\)</span>, will be interpreted as stoachistcity in communitiy composition. Each of these values will be averaged across species. For each fitted model, we thus obtain a vector of four numbers, which sum to 1, which estimate the assembly mechanisms of this metacommunity. Over all the models we will run, we will be able to derive a multivariate proability distribution of assembly mechanisms. As each mechanism itself can range between 0 and 1, their distribution can likely be captured by a beta distribution. The Dirichlet distribution is a multivariate distribution with beta marginals, and thus able to represent this.</p>
</section>
<section id="simulating-typologies" class="level3">
<h3 class="anchored" data-anchor-id="simulating-typologies">Simulating typologies</h3>
<p>The fitted models will be used to simulate new bitoic data.</p>
<!-- non fuzzy -->
<!-- fuzzy     -->
</section>
<section id="evaluating-typologies" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-typologies">Evaluating typologies</h3>
<p>We will evaluate each typology with a selection of recommended or practically used methods. All methods are shortly introduced below. Consider a set of <span class="math inline">\(N\)</span> sites classified into <span class="math inline">\(T\)</span> distinct types <span class="math inline">\(t_1, t_2, \dots, t_T \in \tau\)</span>, where <span class="math inline">\(\tau\)</span> represents the complete typology system. Let <span class="math inline">\(x_i\)</span> be a site and <span class="math inline">\(\tau(x_i)\)</span> the function that returns its type assignment. For any site <span class="math inline">\(x_i\)</span>, let <span class="math inline">\(\bar{d}(x_i,\mathbf{x}_{\tau(x_i)})\)</span> represent the mean dissimilarity between <span class="math inline">\(x_i\)</span> and all other sites within its assigned type <span class="math inline">\(\tau(x_i)\)</span>. For any other type <span class="math inline">\(t_x \in \tau \setminus \{\tau(x_i)\}\)</span>, let <span class="math inline">\(\bar{d}(x_i,\mathbf{x}_{t_x})\)</span> denote the mean dissimilarity between <span class="math inline">\(x_i\)</span> and all sites in type <span class="math inline">\(t_x\)</span>. The neighbor type of <span class="math inline">\(x_i\)</span>, denoted as <span class="math inline">\(b(x_i)\)</span>, is defined as the type (excluding <span class="math inline">\(\tau(x_i)\)</span>) that minimizes the mean dissimilarity: <span class="math display">\[b(x_i)=\underset{x \in \tau \setminus \{\tau(x_i)\}}{argmin}\ \bar{d}(x_i,\mathbf{s}_{t_x})\]</span> The silhouette width quantifies how well <span class="math inline">\(x_i\)</span> fits within its assigned type compared to its neighbor type. For site <span class="math inline">\(x_i\)</span>, it is computed as:<br>
<span class="math display">\[sw(x_i) = \dfrac{\bar{d}(x_i, \mathbf{x}_{b(x_i)}) - \bar{d}(x_i,\mathbf{x}_{\tau(x_i)})}{max\big\{\bar{d}(x_i, \mathbf{x}_{b(x_i)}), \bar{d}(x_i,\mathbf{x}_{t_{\tau(x_i)}})\big\}}\]</span></p>
<p>The Average Silhouette Width (ASW) is calculated as the mean of individual silhouette widths across all sites: <span class="math display">\[ASW = \dfrac{1}{N}\Sigma_{i=1}^N sw(x_i)\]</span> The ASW ranges from -1 to 1, where -1 indicates the poorest possible type assignments and 1 represents optimal type assignments.</p>
<!-- Classification Strength -->
<p>The Classification Strength <span class="citation" data-cites="vansickleUsingMeanSimilarity1997">[CS, @vansickleUsingMeanSimilarity1997]</span> provides another measure to evaluate typology systems by comparing similarities within and among types. Given a similartiy matrix <span class="math inline">\(\mathbf{S}\)</span> with elements <span class="math inline">\(s_{ij}\)</span> where <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> index over sites, we define the within type similarity for type T as: <span class="math display">\[W_T = \dfrac{1}{K_T} \sum_{i = 1}^N \sum_{\substack{j = 1\\ j \neq i}}^N s_{ij} \times \epsilon_{ij}\]</span></p>
<p>where <span class="math inline">\(\epsilon_{ij} = 1\)</span> if sites <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> both belong to type <span class="math inline">\(T\)</span> (i.e., <span class="math inline">\(\tau(s_i)=\tau(s_j) = T\)</span>), and <span class="math inline">\(0\)</span> otherwise. <span class="math inline">\(K_T\)</span> represents the total number of pairwise comparisons within type <span class="math inline">\(T\)</span>, ensuring <span class="math inline">\(W_T\)</span> represents the mean similarity among sites of type <span class="math inline">\(T\)</span>. The among-type similarity for type <span class="math inline">\(T\)</span> is defined analogously: <span class="math display">\[B_T = \dfrac{1}{L_T} \sum_{i = 1}^N \sum_{\substack{j = 1\\ j \neq i}}^N s_{ij} \times (1-\epsilon_{ij})\]</span> where <span class="math inline">\(L_T\)</span> is the number of comparisons between sites in type <span class="math inline">\(T\)</span> and sites in all other types The type-specific classification strength is calculated as: <span class="math display">\[CS_t = W_t - B_t\]</span> This measure quantifies how much more similar sites are to others within their assigned type compared to sites in different types. The difference to SW is, that CS considers all other types and not only the neighbor. The Classification Strength for the complete typology system is computed as a weighted average of type-specific Classification Strengths: <span class="math display">\[CS = \sum_t^T \dfrac{n_t}{N} CS_t\]</span> where <span class="math inline">\(n_t\)</span> is the number of sites in type <span class="math inline">\(t\)</span> and <span class="math inline">\(N\)</span> is the total number of sites. Similar to the ASW, CS values range from -1 to 1, with higher values indicating more distinct and well-defined types.</p>
<!-- ANOSIM -->
<p>The Analysis of Similarities <span class="citation" data-cites="clarkeNonparametricMultivariateAnalyses1993">[ANOSIM, @clarkeNonparametricMultivariateAnalyses1993]</span> evaluates typology systems using ranked similarities rather than raw similarity values. Let <span class="math inline">\(\mathbf{S}_{rank}\)</span> be the matrix of ranked similarities derived from <span class="math inline">\(\mathbf{S}\)</span>, where lower ranks are assigned to higher similarities. For any pair of sites <span class="math inline">\((i,j)\)</span>, the element <span class="math inline">\(s^{rank}{ij}\)</span> represents the rank of the corresponding similarity <span class="math inline">\(s_{ij}\)</span>. We define <span class="math inline">\(\bar{r}_W\)</span> as the mean rank of within-type similarities and <span class="math inline">\(\bar{r}_B\)</span> as the mean rank of between-type similarities. The ANOSIM R statistic is computed as: <span class="math display">\[R = (\bar{r}_B - \bar{r}_W)/(M/2)\]</span> where <span class="math inline">\(M = N(N-1)/2\)</span> Like ASW and CS, the ANOSIM R statistic ranges from -1 to 1 A permutational <em>p</em>-value for R can be computed.</p>
<p>Permutational multivariate analysis of variances <span class="citation" data-cites="andersonNewMethodNonparametric2001">[PERMANOVA, @andersonNewMethodNonparametric2001]</span> evaluates typology systems by analyzing the variance in dissimilarities among sites. For a dissimilarity matrix <span class="math inline">\(\mathbf{D}\)</span> with elements <span class="math inline">\(d_{ij}\)</span>, we compute two sums of squares: The total sum of squares: <span class="math display">\[SS_{total} = \dfrac{1}{N}\sum_{i=1}^{N-1} \sum_{j=i+1}^{N} d_{ij}^2\]</span></p>
<p>The within-type sum of squares: <span class="math display">\[SS_{within} = \dfrac{1}{N}\sum{i=1}^{N-1} \sum{j=i+1}^{N} d_{ij}\times \epsilon_{ij}\]</span></p>
<p>The pseudo F-ratio is then computed as: <span class="math display">\[F = \dfrac{SS_{within} / (T-1)}{SS_{total} / (N-T)}\]</span> Larger F-ratios indicate greater separation between type centroids in multivariate space. The statistical significance of the F-ratio can be assessed through a permutation test.</p>
<!-- non geometric methods -->
<p>Non-geometric measures evaluate typology systems directly from abundance or occurrence data, without requiring similarity metrics. These include the indicator species analysis <span class="citation" data-cites="dufreneSpeciesAssemblagesIndicator1997">[IndVal, @dufreneSpeciesAssemblagesIndicator1997]</span>, Indicator Species Analysis Minimizing Intermediate Constancies <span class="citation" data-cites="robertsLabdsvOrdinationMultivariate2023">[ISAMIC, @robertsLabdsvOrdinationMultivariate2023]</span>, and Area Under the ζ-diversity Decline Curve <span class="citation" data-cites="jupkeEuropeanRiverTypologies2023">[AUCζ, @jupkeEuropeanRiverTypologies2023]</span>.<br>
<!--IndVal --> The indicator species analysis combines two components for each taxon <span class="math inline">\(h\)</span> in type <span class="math inline">\(t\)</span>: concentration (<span class="math inline">\(A_{ht}\)</span>) and relative frequency (<span class="math inline">\(F_{ht}\)</span>). A perfect indicator (IndVal = 1.0) occurs exclusively in one type (perfect concentration) and is present in all samples of that type (maximum frequency). For the group-equalized IndVal variant, which accounts for uneven sample sizes across types <span class="citation" data-cites="decaceresImprovingIndicatorSpecies2010">[@decaceresImprovingIndicatorSpecies2010]</span>, we compute the concentration component as: <span class="math display">\[A^g_{ht} = \frac{a^g_t}{a^g}\]</span> where <span class="math inline">\(a^g_t = \frac{N}{k}\sum_{i \in t}(a_i/N_i)\)</span> is the group-equalized sum of abundances in type <span class="math inline">\(t\)</span>, and <span class="math inline">\(a^g = \frac{N}{k}\sum_{i \in K}(a_i/N_i)\)</span> is the total group-equalized abundance. The frequency component as: <span class="math display">\[B_{ht} = \frac{n_{ht}}{N_t}\]</span> where <span class="math inline">\(n_{ht}\)</span> is the number of occurrences of taxon <span class="math inline">\(h\)</span> in type <span class="math inline">\(t\)</span>, and <span class="math inline">\(N_t\)</span> is the total number of sites in type <span class="math inline">\(t\)</span>. The group-equalized IndVal for taxon <span class="math inline">\(h\)</span> in type <span class="math inline">\(t\)</span> is then: <span class="math display">\[IndVal^g_{ht} = \sqrt{A^g_{ht} \times B_{ht}} \times 100\]</span> For each species, only the highest IndVal is considered. <span class="math display">\[IndVal^g_h = \max_{t}(IndVal^g_{ht})\]</span> Statistical significance of each IndVal is assessed through a permutation test. Since multiple tests are performed (one for each taxon), the resulting p-values are adjusted using Holm’s step-down procedure to control for multiple comparisons <span class="citation" data-cites="westfallResamplingbasedMultipleTesting1993">[@westfallResamplingbasedMultipleTesting1993]</span>. Two metrics evaluate the overall quality of the typology system: 1. The proportion of significant indicator taxa (at <span class="math inline">\(\alpha = 0.05\)</span>), denoted as <span class="math inline">\(N_{sig}\)</span>: <span class="math display">\[N_{sig}=\frac{1}{H}\sum_{h=1}{H}I(p_h&lt;0.05)\]</span> where <span class="math inline">\(I()\)</span> is the indicator function, <span class="math inline">\(H\)</span> the number of species and <span class="math inline">\(p_h\)</span> is the adjusted p-value for taxon <span class="math inline">\(h\)</span>. 2. The mean adjusted p-value across all taxon-type combinations: <span class="math display">\[\bar{p} = \frac{1}{H} \sum_{h=1}^H p_h\]</span></p>
<p>A superior typology system is characterized by a higher <span class="math inline">\(N_{sig}\)</span> and a lower <span class="math inline">\(\bar{p}\)</span>.</p>
<p>The Indicator Species Analysis Minimizing Intermediate Constancies (ISAMIC) evaluates how consistently species occur within types. For each taxon <span class="math inline">\(h\)</span> and type <span class="math inline">\(t\)</span>, we calculate: <span class="math display">\[ISAMIC = \frac{\sum_{h=1}^{H}\left\{\left(2\sum_{t=1}^{T}|F_{ht}-0.5|\right)/T\right\}}{N}\]</span> The metric quantifies the predictability of species occurrence patterns. Values close to 1 indicate that species tend to be either consistently present or consistently absent within types Values close to 0 indicate that species occurrences are unpredictable, with frequencies close to 0.5 Higher ISAMIC values suggest a more effective typology system.</p>
<p>The Area Under the Zeta diversity Curve (AUCζ) quantifies the rate at which shared taxa decrease across an increasing number of sampling sites. For a set of sites, the zeta (ζ) diversity of degree <span class="math inline">\(q\)</span> represents the mean number of species shared across <span class="math inline">\(q\)</span> sites <span class="math display">\[\zeta_q = \mathbb{E}\left[\bigcap_{j=1}^q y_j\right]\]</span> where <span class="math inline">\(y_j\)</span> represents the set of species in site <span class="math inline">\(j\)</span>. For any typology system, we compute the ζ-diversity within-types <span class="math inline">\(\zeta^w_q\)</span> using only sites from the same type and the ζ-diversity between-types <span class="math inline">\(\zeta^b_q\)</span> using sites from different types. As ζ-diversity declines monotonically with increasing <span class="math inline">\(q\)</span>, we can compute the area under the decline curves to quantify the speed and magnitude of turnover. The AUCζ for is calculated as: <span class="math display">\[AUC\zeta^w = \frac{1}{\zeta_1}\sum_{q=2}^{10} \frac{\zeta^w_i + \zeta^w_{i-1}}{2}\]</span> <span class="math display">\[AUC\zeta^b = \frac{1}{\zeta_1}\sum_{q=2}^{10} \frac{\zeta^b_i + \zeta^b_{i-1}}{2}\]</span> We devide by <span class="math inline">\(zeta_1\)</span> to obtain results that are independent of species richness. The effectiveness of a typology system can be quantified by the ratio: <span class="math display">\[\Delta AUC\zeta = \frac{AUC\zeta^w}{AUC\zeta^b}\]</span> where values &gt; 1 indicate lower turnover within types than between types.</p>
<p>Zeta (ζ) diversity represents the number of species common to a specified number of sites <span class="citation" data-cites="huiZetaDiversityConcept2014">[@huiZetaDiversityConcept2014]</span>.</p>
<p>To calculate AUCζ, we plot the ζ diversity values against their corresponding degrees and measure the area under the resulting curve. This area serves as an indicator of both the magnitude and rate of species turnover across sites. While this metric was initially introduced by <span class="citation" data-cites="jupkeEuropeanRiverTypologies2023">@jupkeEuropeanRiverTypologies2023</span>, our approach will extend their methodology by incorporating a comparative analysis. Specifically, we will evaluate the AUCζ values derived from mixed-type site combinations against those from single-type sites.</p>
</section>
<section id="deriving-benchmarks" class="level3">
<h3 class="anchored" data-anchor-id="deriving-benchmarks">Deriving benchmarks</h3>
</section>
<section id="software" class="level3">
<h3 class="anchored" data-anchor-id="software">Software</h3>
<p>To ensure replicability, we will use the groundhog R package () to use the packageversions that were available on the (add date). Posterior checks were conducted with coda … (), Data wrangling was done with data.table, and tidyverse packages.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>